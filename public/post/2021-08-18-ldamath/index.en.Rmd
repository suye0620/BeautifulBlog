---
title: LDA主题模型数学推导
author: Ye.S
date: '2021-08-18'
slug: [ldamath]
categories:
  - 文章
tags:
  - math
  - NLP
  
cover: /img/LDAMath/LDAcover.jpg
output:
  blogdown::html_page:
    toc: true
  
summary: "关于LDA主题模型的数学推导过程"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F,warning = F,error = F)
```

## 前言

$\quad$在机器学习术语中，LDA既指Linear Discriminant Analysis(线性判别分析)，又指Latent Dirichlet Allocation(隐含迪利克雷分布)。在这篇文章中，我们研究的将是后者。LDA是在我大二下第一次做市场调 查大赛时进入我的视线的。当时应用此法做主题-关键词提取时，我虽然感觉其原理晦涩难懂、读起来脑壳 痛，但是从做出来的效果来看用此法进行简单的文本关键词抽取是非常省事的。之后，我在完成数据科学 概论、Python数据分析这两门课程时，又反复琢磨此法原理，但还是徒劳无功。现在，我决心从头到尾梳理 一遍此法的数学原理，将其功力公诸于世。

<center>

<img alt = '菜鸟每天飞过' src = "./pic/cainiao.jpg" width=40%>

</center>

## 统计文本建模

$\quad$我们日常生活中产生了大量的文本，如果每一个文本存储为一篇文档，那么每篇文档从人的观察来说就是有序的词的序列$d = (w_1,w_2,...,w_n)$。

```{r ,fig.align="center",fig.cap="包含m篇文档的语料库"}
knitr::include_graphics("./pic/pic_1-1.jpg")

```

$\quad$统计文本建模的目的就是探寻这些观察到语料库中的词序列是如何生成的。LDA就是一种优秀的统计文本建模方法。在讨论LDA模型前，我们先研究一下文本主题模型------Unigram Model以及LDA的前身PLSA。

## Unigram Model(一元语法模型)

### Unigram Model的概念

$\quad$假设我们的词典(语料库corpus)中一共有$V$个词$v_1,v_2,...,v_V$，那么简单的Unigram Model就认为文本是基于如下规则产生的。

| Unigram Model                                                                                                               |
|:----------------------------------------------------------------------------------------------------------------------------|
| 1\. 假设有一个骰子，这个骰子有$V$个面，每个面对应一个词，各个面朝上的概率不一；                                                 |
| 2\. 每抛掷一次骰子，抛出的面就对应地产生一个词；如果一篇文档中有$n$个词，产生一篇文档就要独立地抛掷$n$次骰子产生这$n$个词。 |

$\quad$这个骰子的各个面的概率记为$\overrightarrow{p} = (p_1,p_2,...,p_V)$，其中$\sum_{k = 1}^Vp_k = 1$，所以每次投掷骰子的过程类似于一个抛硬币的贝努利实验，只是贝努利实验中我们抛的是一个"两面的骰子"，而此处抛掷的是一个$V$面的骰子，我们把抛这个$V$面骰子的实验记为$w \sim Mult(V,\overrightarrow{p})$。

说明：Multinomial distribution------多项分布，$w \sim Mult(V,\overrightarrow{p})$的含义为，在骰子各面或者说语料库中各个词出现的概率给定的情况下($\overrightarrow{p}$)，我们进行一次生成word的实验，则这个word符合多项分布。

### 补充1：多项分布

$\quad$多项分布，Wiki百科的定义是这样的：假设一个人做了一个实验，他从一个装有$k$种不同颜色球的袋子里有放回地摸出$n$个球，对于同一种颜色的球，被摸到的概率都是相等的。然后，我们用$X_i$表示摸到第$i$($1 \leq i \leq k$)种颜色球的个数，用$p_i$表示实验中摸到第$i$种颜色球的概率，则这个实验的结果(一系列$X_i$)满足多项分布，有：

<!-- 公式区 -->
\begin{align*}

& P(X_1 = x_1,X_2=x_2,…,X_k = x_k) \\
& =
\begin{cases}
\frac{n!}{x_1!\cdots x_k!}p_1^{x_1}\times \cdots \times p_k^{x_k} &, & \text{when $\sum_{i = 1}^k x_i = n$,}\\
0 &, & \text{otherwise.}
\end{cases}\\

& \text{其中$x_1,X_2=x_2,…,X_k = x_k$均为非负整数}
\end{align*}

$\quad$对于一篇文档$d = \overrightarrow{w} = (w_1,w_2, \cdots ,w_n)$，该文档被生成的概率就是
$$p(\overrightarrow{w}) = p(w_1,w_2, \cdots ,w_n) = p(w_1)p(w_2)\cdots p(w_n)$$
而文档和文档之间我们认为是独立的，所以如果语料中有多篇文档$W = (\overrightarrow{w_1},\overrightarrow{w_2}, \cdots,\overrightarrow{w_m})$(用向量表示一个corpus)，则该语料的概率是
$$
p(W) = p(\overrightarrow{w_1})p(\overrightarrow{w_2})\cdots p(\overrightarrow{w_n})
$$

$\quad$在Unigram Model中，我们假设了文档之间是独立可交换的，而文档中的词也是独立可交换的，所以一篇文档相当于一个袋子，里面装了一些词，而词的顺序信息就无关紧要了，这样的模型也称为词袋模型(Bag-of-words)。

$\quad$假设语料中总的词频是$N$(所有词的词频加总，我的理解是我们做上述多项分布实验的次数)，在所有的$N$个词中，如果我们关注每个词$w_i$的发生次数$n_i$(词频)，那么$\overrightarrow{n} = (n_1,n_2, \cdots ,n_V),其中\sum_{k = 1}^{V}n_k = N$就是一个多项分布：

<!-- 公式区 -->
\begin{align*}
\overrightarrow{n} \sim Mult(N,\overrightarrow{p})\\

p(\overrightarrow{n}) 
= \binom{N}{\overrightarrow{n}}\prod_{k = 1}^{V}p_k^{n_k}\\
\end{align*}

$\quad$这里关于$\binom{N}{\overrightarrow{n}}$，我想多说几句。首先这种写法我只在《LDA数学八卦》上见过，个人觉得有点迷惑。所以根据多项分布的计算公式，个人觉得它是这个含义：

<!-- 公式区 -->
\begin{align*}

\binom{N}{\overrightarrow{n}}
&= C_N^{n_1} C_{N-{n_1}}^{n_2} C_{N-{n_1}-{n_2}}^{n_3} \cdots \\
&= \frac{N!}{n_1!n_2! \cdots n_V!}
\end{align*}

$\quad$承上面的假设，并且语料库中各文档(设有m篇)相互独立，此时语料库的概率$p(\overrightarrow{w})$是：
$$
p(W) = p(\overrightarrow{w_1})p(\overrightarrow{w_2}) \cdots p(\overrightarrow{w_m}) =  \prod_{k=1}^{V}p_k^{n_k} \\
注：因为词袋模型忽略词序，\\
故直接概率连乘。
$$

$\quad$现在，我们的任务就是用手中的文本(样本)估计Unigram模型中的参数$\overrightarrow{p}$，也就是计算语料库中各个词出现的概率是多大。按照频率派的观点，使用MLE最大化$P(W)$。下面给出一个详细的推导步骤：

1. 取似然函数为
$$
L(\overrightarrow{p})
= \prod_{k=1}^{V}p_k^{n_k}\\
$$
2. 对数似然函数为

$$
lnL(\overrightarrow{p}) = \sum_{k=1}^{V}n_kln(p_k)
$$

3. 要使$L(\overrightarrow{p})$最大，即要使$lnL(\overrightarrow{p})$最大。而$lnL(\overrightarrow{p})$这个多元函数是有约束条件的：$\sum_{k=1}^V n_k = N$和$\sum_{k=1}^{V}p_k = 1$，故用拉格朗日乘数法求之：

<!-- 公式区 -->

\begin{align*}
令F(\overrightarrow{p},\lambda) = \sum_{k=1}^{V}n_k ln(p_k) - \lambda(\sum_{k=1}^{V}p_k -1)\\
\end{align*}

\begin{align*}
再令
\begin{cases}
\frac{\partial F}{\partial p_k}
&=& \frac{n_k}{p_k} - \lambda =0\\
\frac{\partial F}{\partial \lambda}
&=& \sum_{k=1}^{V}p_k -1 =0
\end{cases}
\end{align*}

\begin{align*}
得
\begin{cases}
p_k = \frac{n_k}{\lambda}\\
\sum_{k=1}^{V}p_k = 1
\end{cases}
\end{align*}

\begin{align*}
故
\sum_{k=1}^{V}p_k = 
\sum_{k=1}^{V}\frac{n_k}{\lambda} = 
\frac{\sum_{k=1}^{V}n_k}{\lambda} = 
\frac{N}{\lambda} = 1
\end{align*}

\begin{align*}
即有
\lambda = N\\
\hat{p_k} = \frac{n_k}{\lambda} = \frac{n_k}{N}
\end{align*}

### 补充2：先验分布、后验分布、共轭分布

$\quad$以上模型，均基于频率学派观点。贝叶斯统计学派会对此有不同的意见。在他们看来，一切参数都是随机变量，上述Unigram Model中的$\overrightarrow{p}$不是唯一固定的，它是一个随机变量。基于这样的想法，我们对Unigram Model的规则进行修改：

|贝叶斯版本的Unigram Model|
|:---|
|1. 有一个装有无穷多个骰子的坛子，每个骰子都有$V$个面，每个面对应一个词，各个面朝上的概率不一。并且各个骰子代表的$\overrightarrow{p}$不一样；|
|2. 我们从坛子里抽出一个骰子，即选择一个$\overrightarrow{p}$，然后用这个骰子不断地抛，直至产生了语料中的所有词(即达到了上面那个语料库词频向量$\overrightarrow{n}$)。|

$\quad$这个坛子里面，骰子可以是无穷多个，有些类型的骰子多，有些类型的骰子少。所以从概率分布的角度看，坛子里面骰子代表的$\overrightarrow{p}$服从一个概率分布$P(\overrightarrow{p})$，这个分布称为参数$\overrightarrow{p}$的先验分布。

```{r,fig.align='center',fig.cap="两种观点下Unigram Model的对比",out.width='50%',fig.show='hold'}
knitr::include_graphics(c("./pic/Unigram1.jpg","./pic/Unigram2.jpg"))

```

$\quad$下面我们介绍一下先验分布、后验分布、共轭分布的概念，为我们往后的理解扫除一些障碍。

$\quad$共轭分布(conjugate distribution)的概率中一共涉及到三个分布：先验、似然和后验，如果由先验分布和似然分布所确定的后验分布与该先验分布属于同一种类型的分布，则该先验分布为似然分布的共轭分布，也称为共轭先验。

$\quad$比较绕嘴，下面从公式来理一下思路。假设变量$x$服从分布$P(x| \theta )$，其观测样本为$X={x_1,x_2,...,x_m}$，参数$θ$服从先验分布$Π(θ)$。那么后验分布为
$$P(θ|X)=\frac{Π(θ)P(X|θ)}{P(X)}$$

$\quad$如果后验分布$P(θ|X)$与先验分布$Π(θ)$是同种类型的分布，则称先验分布$Π(θ)$为似然分布$P(X|θ)$的共轭分布(直观一点就是上面那个贝叶斯公式的分子里的两个)。

$\quad$比较常用的几个例子有：高斯分布是高斯分布的共轭分布，Beta分布是二项分布的共轭分布，Dirichlet分布是多项分布的共轭分布。共轭分布不仅使求后验分布计算简单，更重要的是保留了先验分布的类型，使概率估计更加准确。 

$\quad$关于Dirichlet分布是Multinomial分布的共轭分布这点，我们在此不作过多的涉及，详细推导可以参考《LDA数学八卦》这本书。但是为了下面LDA模型阐述的方便，我们交代一下Dirichlet-Multinomial的共轭关系以及Beta/Dirichlet分布的一个性质。

#### Dirichlet-Multinomial的共轭关系

$\quad$首先我们要强调的是贝叶斯参数估计的基本过程是：

<center><strong>先验分布+数据的知识(实验后样本的情况) = 后验分布</strong></center>

$\quad$其次我们给出两个分布的数学形式，一般形式的Dirichlet分布定义如下

\begin{align*}
Dir(\overrightarrow{p}|\overrightarrow{\alpha}) = 
\frac{\Gamma(\sum_{k=1}^K) \alpha_k}{\prod_{k=1}^K \Gamma(\alpha_k)}
\prod_{k=1}^K p_k^{\alpha_k - 1}
\end{align*}

*注:这里的K代指进行多项分布实验的次数，或者叫维度吧。在我们UnigramModel的语境中，K = V，即K为语料库中词语总数V*

$\quad$对于给定的$\overrightarrow{p}$和$N$，多项分布的定义为

\begin{align*}
Mult(\overrightarrow{n}|\overrightarrow{p},N) = \binom{N}{\overrightarrow{n}}\prod_{k = 1}^{K}p_k^{n_k}\\
\end{align*}

*注:这里的K在我们UnigramModel的语境中，与上面一致。K = V，即K为语料库中词语总数V。另外，笔者查阅教科书，并未发现这种分布写法，推测这应当是一种简单写法。根据Wiki百科关于多项分布的定义，这种“分布”应该是以下的简写：*($\overrightarrow{n}$是取值离散的，只有分布律一说)

\begin{align*}
& \overrightarrow{n} \sim Mult(\overrightarrow{p},N),其中sum(\overrightarrow{n})=N\\
& P(\overrightarrow{n}) = \binom{N}{\overrightarrow{n}}\prod_{k = 1}^{K}p_k^{n_k}
\end{align*}

$\quad$最后，$Mult(\overrightarrow{n}|\overrightarrow{p},N)$和$Dir(\overrightarrow{p}|\overrightarrow{\alpha})$之间的共轭关系，不严谨地交代如下

1. 以三维为例，我们要猜测参数$\overrightarrow{p} = (p_1,p_2,p_3)$，其先验分布为$Dir(\overrightarrow{p}|\overrightarrow{k})$；

2. 数据$Y_i$落到$[0,p_1),[p_1,p_2),[p_2,1]$三个区间的个数分别为$m_1,m_2,m_3$，所以$\overrightarrow{m} = (m_1,m_2,m_3)$服从多项分布$Mult(\overrightarrow{m}|\overrightarrow{p})$

3. 在给定了来自数据提供的知识$\overrightarrow{m}$后，$\overrightarrow{p}$的后验分布变为$Dir(\overrightarrow{p}|\overrightarrow{k}+\overrightarrow{m})$

$\quad$以上贝叶斯分析过程的简单表述就是：
$$
Dir(\overrightarrow{p}|\overrightarrow{k})(先验)+MultCount(\overrightarrow{m})(共轭) = Dir(\overrightarrow{p}|\overrightarrow{k}+\overrightarrow{m})(后验)
$$

$\quad$令$\overrightarrow{k} = \overrightarrow{\alpha}$，即把先验分布$Dir(\overrightarrow{p}|\overrightarrow{k})$从整数集合延拓到实数集合，更一般的关系就如下：

$$
Dir(\overrightarrow{p}|\overrightarrow{\alpha})+MultCount(\overrightarrow{m}) = Dir(\overrightarrow{p}|\overrightarrow{\alpha}+\overrightarrow{m})
$$

$\quad$上面的式子描述的就是Dirichlet-Multinomial的共轭关系，我们还可以从3维往更高的维度上继续推广，就可以得到更高维度的Dirichlet-Multinomial的共轭。

$\quad$看到这里，我们已经能够察觉到LDA模型中的参数$\alpha,\beta$是哪里来的了——没错，它们来自于多项分布的共轭分布：Dirichlet分布。它们是Dirichlet分布产生$\overrightarrow{p}$的重要条件。

#### Beta/Dirichlet分布的一个性质

$\quad$如果$\overrightarrow{p} \sim Beta(t|\alpha,\beta)$，则

（未完待续······）
